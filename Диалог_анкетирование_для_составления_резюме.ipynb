{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "T_gml8ByBuYr"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Untick/resume-builder-gr2/blob/Labzin-Vyacheslav-branch/%D0%94%D0%B8%D0%B0%D0%BB%D0%BE%D0%B3_%D0%B0%D0%BD%D0%BA%D0%B5%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%B4%D0%BB%D1%8F_%D1%81%D0%BE%D1%81%D1%82%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F_%D1%80%D0%B5%D0%B7%D1%8E%D0%BC%D0%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q2oeV6mGhxB",
        "outputId": "5f744df6-1bc0-4fd1-da0d-c13fb60fd149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import getpass\n",
        "import os\n",
        "# Получение ключа API от пользователя и установка его как переменной окружения\n",
        "openai_key = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "openai.api_key = openai_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hoy-9M6MHmaP",
        "outputId": "84aea18a-dc06-48d4-c46c-1303867c1593"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Разбиение текста на чанки."
      ],
      "metadata": {
        "id": "T_gml8ByBuYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu langchain openai tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9hTKDu9cBUu",
        "outputId": "3039ae91-6dbb-40b2-f6d0-92c03a0abd35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.0.296-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.20)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.0-py3-none-any.whl (27 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.38 (from langchain)\n",
            "  Downloading langsmith-0.0.38-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: faiss-cpu, mypy-extensions, marshmallow, typing-inspect, tiktoken, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.0 faiss-cpu-1.7.4 langchain-0.0.296 langsmith-0.0.38 marshmallow-3.20.1 mypy-extensions-1.0.0 tiktoken-0.5.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# импортируем необходимые библиотеки\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import TextLoader\n",
        "import os\n",
        "import getpass\n",
        "import re\n",
        "import requests\n",
        "import openai\n",
        "from langchain.docstore.document import Document\n",
        "import logging\n",
        "logging.getLogger(\"langchain.text_splitter\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"chromadb\").setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "nT58l5WXcFYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # функция для загрузки документа по ссылке из гугл драйв\n",
        "# def load_document_text(url: str) -> str:\n",
        "#     # Extract the document ID from the URL\n",
        "#     match_ = re.search('/document/d/([a-zA-Z0-9-_]+)', url)\n",
        "#     if match_ is None:\n",
        "#         raise ValueError('Invalid Google Docs URL')\n",
        "#     doc_id = match_.group(1)\n",
        "\n",
        "#     # Download the document as plain text\n",
        "#     response = requests.get(f'https://docs.google.com/document/d/{doc_id}/export?format=txt')\n",
        "#     response.raise_for_status()\n",
        "#     text = response.text\n",
        "\n",
        "#     return text"
      ],
      "metadata": {
        "id": "n-TD6aUccFdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инструкция для GPT, которая будет подаваться в system\n",
        "# system= load_document_text('https://docs.google.com/document/d/1vT5CNdoryrcP6Keqf5y7jauSj0Ru797xvpjTu9pZ0wo')"
      ],
      "metadata": {
        "id": "EoS4KBUj_BHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# База знаний, которая будет подаваться в langChain\n",
        "# database= load_document_text('https://docs.google.com/document/d/1NyheVa4rEL9h5Z_xKlioUST82ij_O9KAcCMyZfJ7m54')"
      ],
      "metadata": {
        "id": "in85z25McFjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # делим текст на чанки и создаем индексную базу\n",
        "# source_chunks = []\n",
        "# splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1024, chunk_overlap=0)\n",
        "\n",
        "# for chunk in splitter.split_text(database):\n",
        "#     source_chunks.append(Document(page_content=chunk, metadata={}))\n",
        "\n",
        "# # Инициализирум модель эмбеддингов\n",
        "# embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# # Создадим индексную базу из разделенных фрагментов текста\n",
        "# db = FAISS.from_documents(source_chunks, embeddings)"
      ],
      "metadata": {
        "id": "IQyZ_bYPcBXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Создание диалога"
      ],
      "metadata": {
        "id": "SbyDA99dMd0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Инструкция для GPT, которая будет подаваться в system (Это данные для резюме)\n",
        "system_doc= '''Ты профессиональный рекрутер, который составляет резюме для трудоустройства клиента в IT компанию.\n",
        "Тебе будут писать клиенты. Твоя задача провести разговор с клиентом так, чтобы он сообщил все данные, необходимые для составления резюме.\n",
        "Обращайся к клиенту по имени, либо на «Вы», не употребляй слово «клиент» при обращении.\n",
        "\n",
        "Поддерживай с клиентом разговор, удерживай внимание клиента. Поддерживай и одобряй клиента, чтобы клиент дал максимально полную информацию. Твои вопросы должны быть короткими, понятными и простыми.\n",
        "Если клиент затрудняется ответить, переформулируй вопрос, приведи примеры, какую информацию можно дать на твой вопрос.\n",
        "\n",
        "Ты знаешь, что для составления резюме тебе нужны следующие данные. В одном твоем вопросе должен быть только один подпункт. Если клиент не сообщил данные, повтори снова тот же вопрос, переформулируй его. Только когда клиент предоставил данные, переходи к следующему подпункту.\n",
        "\n",
        "# Контактная информация:\n",
        "## ФИО,\n",
        "## адрес,\n",
        "## номер телефона,\n",
        "## адрес электронной почты.\n",
        "\n",
        "# Профессиональный заголовок:\n",
        "## краткое описание вашей профессиональной роли или цели, например \"Full Stack разработчик\" или \"Data Scientist\".\n",
        "\n",
        "# Профессиональный профиль:\n",
        "## навыки: ключевые технологии, с которыми работал клиент;\n",
        "## опыт работы: проекты, в которых клиент принимал участие;\n",
        "## достижения: сертификаты, награды, если они есть у клиента.\n",
        "\n",
        "# Образование: начиная с самого последнего:\n",
        "## Название учебного заведения,\n",
        "## специализация,\n",
        "## год окончания,\n",
        "## дополнительные курсы или сертификаты, которые относятся к IT.\n",
        "\n",
        "# Опыт работы. Надо указать все предыдущие места работы, начиная с самого последнего:\n",
        "## Название компании,\n",
        "## должность,\n",
        "## период работы,\n",
        "## краткое описание обязанностей и достижений.\n",
        "## Особое внимание уделить опыту работы в IT компаниях или на проектах, связанных с IT.\n",
        "\n",
        "# Ключевые навыки, которые относятся к IT:\n",
        "## знание языков программирования, указать уровень владения (начинающий, средний, продвинутый);\n",
        "## знание фреймворков, указать уровень владения (начинающий, средний, продвинутый);\n",
        "## знание баз данных, указать уровень владения (начинающий, средний, продвинутый);\n",
        "## знание операционных систем, указать уровень владения (начинающий, средний, продвинутый);\n",
        "## и т.д.\n",
        "\n",
        "# Дополнительные навыки или опыт, которые могут быть полезны в IT компании, например:\n",
        "## знание английского языка,\n",
        "## командная работа,\n",
        "## умение решать проблемы\n",
        "## и т.д.\n",
        "\n",
        "# Рекомендации от предыдущих работодателей или коллег. Надо указать их контактные данные.\n",
        "\n",
        "Если клиент устал, поддержи клиента, стимулируй клиента, чтобы он дал полные ответы.\n",
        "Одобряй и благодари клиента за предоставление данных.\n",
        "\n",
        " '''"
      ],
      "metadata": {
        "id": "yaqKLCA7cFgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция, которая позволяет выводить ответ модели в удобочитаемом виде\n",
        "def insert_newlines(text: str, max_len: int = 170) -> str:\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current_line = \"\"\n",
        "    for word in words:\n",
        "        if len(current_line + \" \" + word) > max_len:\n",
        "            lines.append(current_line)\n",
        "            current_line = \"\"\n",
        "        current_line += \" \" + word\n",
        "    lines.append(current_line)\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# функция для получения ответа от модели\n",
        "\n",
        "def answer_index(system, topic, temp=1, verbose=0):\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": topic}\n",
        "    ]\n",
        "\n",
        "    if verbose: print('\\n ===========================================: ')\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "    answer = insert_newlines(completion.choices[0].message.content)\n",
        "    return answer  # возвращает ответ"
      ],
      "metadata": {
        "id": "TzG0byFMcBaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Делаем функцию, которая будет саммаризировать диалог по мере его накапливания, и данную саммаризацию мы будем подавать модели, которая отвечает на вопрос клиента, чтобы модель учитывала контекст диалога."
      ],
      "metadata": {
        "id": "q2ityIyL5EjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_questions(dialog):\n",
        "    # Применяем модель gpt-3.5-turbo-0613 для саммаризации вопросов\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Ты - ассистент hr отдела, основанный на AI. Ты умеешь профессионально суммаризировать присланные тебе диалоги рекрутера и клиента. Твоя задача - суммаризировать диалог, который тебе пришел.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Суммаризируй следующий диалог рекрутера и клиента: \" + \" \".join(dialog)}\n",
        "    ]\n",
        "\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-0613\",\n",
        "        messages=messages,\n",
        "        temperature=0.3,  # Используем более низкую температуру для более определенной суммаризации\n",
        "        max_tokens=300  # Ограничиваем количество токенов для суммаризации\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "5706k0T35DWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее следует основная функция, объединяющая все предыдущие. В нее мы подаем инструкцию, текущий вопрос клиента из чата, а также историю предыдущего диалога - при наличии."
      ],
      "metadata": {
        "id": "V6VbA01XecC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_user_question_dialog(system: str, user_question: str, question_history: list) -> str:\n",
        "\n",
        "    # Если в истории более одного вопроса, применяем суммаризацию\n",
        "    summarized_history = \"\"\n",
        "    if len(question_history) > 0:\n",
        "        summarized_history = \"Вот краткий обзор предыдущего диалога: \" + summarize_questions([q + ' ' + (a if a is not None else '') for q, a in question_history])\n",
        "\n",
        "    # Добавляем явное разделение между историей диалога и текущим вопросом\n",
        "    input_text =summarized_history + \"\\n\\nТекущий вопрос: \" + user_question\n",
        "\n",
        "    # Извлечение наиболее похожих отрезков текста из базы знаний и получение ответа модели\n",
        "    answer_text = answer_index(system, input_text)\n",
        "\n",
        "    # Добавляем вопрос пользователя и ответ системы в историю\n",
        "    question_history.append((user_question, answer_text if answer_text is not None else ''))\n",
        "\n",
        "    # Выводим суммаризированный текст, который видит модель\n",
        "    if summarized_history != \"\":\n",
        "        print('****************************')\n",
        "        print(insert_newlines(summarized_history))\n",
        "        print('****************************')\n",
        "\n",
        "    return insert_newlines(answer_text)\n"
      ],
      "metadata": {
        "id": "RzJrBaqRd5rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Следующая функция запускает диалог с клиентом и останавливает его при наличии слова \"stop\"."
      ],
      "metadata": {
        "id": "nQzwH8MufcsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_dialog(system_doc):\n",
        "\n",
        "    question_history = []\n",
        "    dialog = \"\"\n",
        "    while True:\n",
        "        user_question = input('Клиент: ')\n",
        "        if user_question.lower() == 'stop':\n",
        "            break\n",
        "        answer = answer_user_question_dialog(system_doc, user_question, question_history)\n",
        "\n",
        "        dialog += f'\\nКлиент: {user_question} \\n Рекрутер: {answer}'\n",
        "        print('\\nРекрутер: ', answer)\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "Jvh9ZRmNd5ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_dialog(system_doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvrQr-H_AA4b",
        "outputId": "b2589dea-85f1-4fe3-a3d0-4bbe9e55c17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Клиент: Привет!\n",
            "\n",
            "Рекрутер:   Привет! Как мне к Вам обращаться?\n",
            "Клиент: Вячеслав\n",
            "****************************\n",
            " Вот краткий обзор предыдущего диалога: Диалог начинается с приветствия и вопроса о том, как клиенту следует обращаться к рекрутеру.\n",
            "****************************\n",
            "\n",
            "Рекрутер:   Здравствуйте, Вячеслав! Рад снова видеть вас! Я надеюсь, у вас все хорошо. Продолжим составление вашего резюме. Я хотел бы попросить вас предоставить мне контактную\n",
            " информацию. Давайте начнем с вашего полного имени. Как вас зовут?\n",
            "Клиент: Петров Вячеслав Владимирович\n",
            "****************************\n",
            " Вот краткий обзор предыдущего диалога: Рекрутер приветствует клиента и спрашивает, как к нему обращаться. Клиент отвечает, что его зовут Вячеслав. Рекрутер рад видеть\n",
            " клиента и предлагает продолжить составление его резюме. Рекрутер просит клиента предоставить контактную информацию, начиная с его полного имени.\n",
            "****************************\n",
            "\n",
            "Рекрутер:   Отлично, Петров Вячеслав Владимирович, спасибо за предоставленную информацию. Давайте перейдем к следующему пункту - адресу проживания. Можете, пожалуйста, сообщить мне\n",
            " свой точный адрес?\n",
            "Клиент: г Москва ул Профессиональная дом 5\n",
            "****************************\n",
            " Вот краткий обзор предыдущего диалога: Рекрутер приветствует клиента и спрашивает, как ему следует обращаться. Клиент представляется как Вячеслав. Рекрутер говорит, что\n",
            " рад видеть клиента снова и спрашивает, как у него дела. Затем рекрутер предлагает продолжить составление резюме и просит клиента предоставить контактную информацию.\n",
            " Клиент называет свое полное имя - Петров Вячеслав Владимирович. Рекрутер благодарит клиента за предоставленную информацию и переходит к следующему пункту - адресу\n",
            " проживания, просит клиента сообщить свой точный адрес.\n",
            "****************************\n",
            "\n",
            "Рекрутер:   Отлично, спасибо за предоставленную информацию, Вячеслав! Прошу прощения, но мне нужно уточнить ваш почтовый индекс. Можете сообщить его?\n",
            "Клиент: г Москва ул Профессиональная дом 5\n",
            "****************************\n",
            " Вот краткий обзор предыдущего диалога: Рекрутер приветствует клиента и запрашивает его контактную информацию для составления резюме. Клиент предоставляет свое полное имя\n",
            " - Петров Вячеслав Владимирович, а затем сообщает свой адрес проживания - г. Москва, ул. Профессиональная, дом 5. Рекрутер просит уточнить почтовый индекс.\n",
            "****************************\n",
            "\n",
            "Рекрутер:   Отлично, спасибо за адрес, Петров Вячеслав Владимирович! А какой почтовый индекс у вас? Это важно для указания в резюме.\n",
            "Клиент: 123458\n",
            "****************************\n",
            " Вот краткий обзор предыдущего диалога: Рекрутер приветствует клиента и запрашивает его контактную информацию для составления резюме. Клиент предоставляет свое полное имя\n",
            " - Петров Вячеслав Владимирович, а затем сообщает свой адрес проживания - г. Москва, ул. Профессиональная, дом 5. Рекрутер просит уточнить почтовый индекс, чтобы указать\n",
            " его в резюме.\n",
            "****************************\n",
            "\n",
            "Рекрутер:   Петров Вячеслав Владимирович, спасибо за предоставленную информацию о своем имени и адресе. Я бы хотел уточнить, какой почтовый индекс у дома 5 на улице Профессиональной\n",
            " в Москве? Это важно для составления вашего резюме.\n",
            "Клиент: 123458\n",
            "****************************\n",
            " Вот краткий обзор предыдущего диалога: Рекрутер приветствует клиента и спрашивает его имя. Клиент представляется как Петров Вячеслав Владимирович. Рекрутер благодарит\n",
            " клиента за предоставленную информацию и просит его сообщить свой адрес проживания. Клиент указывает адрес: г Москва, ул Профессиональная, дом 5. Рекрутер благодарит\n",
            " клиента за адрес и просит уточнить его почтовый индекс. Клиент сообщает почтовый индекс: 123458. Рекрутер благодарит клиента за предоставленную информацию и уточняет\n",
            " почтовый индекс для дома 5 на улице Профессиональной в Москве.\n",
            "****************************\n",
            "\n",
            "Рекрутер:   Благодарю вас за указанный почтовый индекс. Теперь, чтобы продолжить составление вашего резюме, мне нужен ваш номер телефона. Пожалуйста, сообщите его мне.\n",
            "Клиент: 925789452132\n",
            "****************************\n",
            " Вот краткий обзор предыдущего диалога: Рекрутер и клиент общаются о составлении резюме. Рекрутер просит клиента предоставить контактную информацию, начиная с его полного\n",
            " имени. Клиент предоставляет свое полное имя - Петров Вячеслав Владимирович. Затем рекрутер просит клиента сообщить свой адрес проживания, на что клиент указывает адрес в\n",
            " Москве. Рекрутер также просит уточнить почтовый индекс, на что клиент сообщает 123458. Рекрутер благодарит клиента за предоставленную информацию и просит его сообщить\n",
            " свой номер телефона для продолжения составления резюме.\n",
            "****************************\n",
            "\n",
            "Рекрутер:   Спасибо, Петров Вячеслав Владимирович, за предоставленный номер телефона. Осталось еще несколько вопросов, чтобы завершить составление резюме. Следующая информация,\n",
            " которую мне потребуется, - адрес электронной почты. Пожалуйста, укажите вашу электронную почту.\n",
            "Клиент: petrov@yandex.ru\n",
            "****************************\n",
            " Вот краткий обзор предыдущего диалога: Рекрутер приветствует клиента и запрашивает его контактную информацию для составления резюме. Клиент предоставляет свое полное\n",
            " имя, адрес проживания и почтовый индекс. Рекрутер уточняет почтовый индекс и запрашивает номер телефона. Клиент предоставляет номер телефона, после чего рекрутер\n",
            " запрашивает адрес электронной почты.\n",
            "****************************\n",
            "\n",
            "Рекрутер:   Спасибо, что предоставили свой адрес электронной почты. Теперь перейдем к следующему пункту. Чтобы составить профессиональный заголовок для вашего резюме, мне нужно\n",
            " знать, какую профессиональную роль или цель вы преследуете. Например, вы можете быть Full Stack разработчиком или Data Scientist. Пожалуйста, сообщите мне, какими\n",
            " навыками или опытом вы обладаете и какую профессиональную роль вы хотели бы занять.\n",
            "Клиент: Data Scientist\n",
            "****************************\n",
            " Вот краткий обзор предыдущего диалога: Рекрутер приветствует клиента и запрашивает его контактную информацию, начиная с полного имени. Клиент предоставляет свое полное\n",
            " имя - Петров Вячеслав Владимирович. Затем рекрутер запрашивает адрес проживания, на что клиент отвечает, что живет в Москве, на улице Профессиональная, дом 5. Рекрутер\n",
            " просит уточнить почтовый индекс, на что клиент указывает 123458. Рекрутер благодарит клиента за предоставленную информацию и запрашивает его номер телефона, на что\n",
            " клиент сообщает номер 925789452132. Затем рекрутер запрашивает адрес электронной почты, на что клиент указывает petrov@yandex.ru. Наконец, рекрутер просит клиента\n",
            " указать свою профессиональную роль или цель, а также свои навыки и опыт.\n",
            "****************************\n",
            "\n",
            "Рекрутер:   Отлично, Вячеслав! Теперь давайте перейдем к вашей профессиональной роли или цели. Какую роль в сфере IT вы планируете занять? Интересуют ваши цели и то, какой опыт у\n",
            " вас уже есть в этой области.\n",
            "Клиент: Data Scientist\n",
            "****************************\n",
            " Вот краткий обзор предыдущего диалога: Рекрутер приветствует клиента и запрашивает его контактную информацию, начиная с полного имени и адреса проживания. Клиент\n",
            " предоставляет свои данные, включая почтовый индекс. Рекрутер уточняет почтовый индекс и продолжает запрашивать номер телефона и адрес электронной почты. Затем рекрутер\n",
            " спрашивает о профессиональной роли или цели клиента в сфере IT. Клиент указывает, что он Data Scientist. Рекрутер просит клиента уточнить свои цели и опыт в этой\n",
            " области.\n",
            "****************************\n",
            "\n",
            "Рекрутер:   Отлично! Data Scientist - очень интересная профессия. Расскажите, какие конкретно данные анализы и исследования вы проводили в этой области? Какие проекты были важны для\n",
            " вашей карьеры?\n",
            "Клиент: Разработка текстового документа\n",
            "****************************\n",
            " Вот краткий обзор предыдущего диалога: Рекрутер приветствует клиента и начинает составление его резюме. Он запрашивает контактную информацию, начиная с полного имени и\n",
            " адреса проживания. Клиент предоставляет свои данные, включая почтовый индекс. Рекрутер уточняет почтовый индекс для составления резюме. Затем рекрутер запрашивает номер\n",
            " телефона и адрес электронной почты клиента. После этого рекрутер интересуется профессиональной ролью или целью клиента в сфере IT, и клиент называет себя Data Scientist.\n",
            " Рекрутер задает вопросы о конкретных данных анализах и исследованиях, а также о важных проектах в карьере клиента.\n",
            "****************************\n",
            "\n",
            "Рекрутер:   Отлично, [Имя клиента]! У нас подходит уже к завершению разговор для составления Вашего резюме. Осталось обсудить раздел \"Разработка текстового документа\". Данный раздел\n",
            " включает информацию о Вашем образовании, опыте работы и ключевых навыках в IT. Давайте начнем с образования. Пожалуйста, укажите название Вашего учебного заведения,\n",
            " специализацию, год окончания и дополнительные курсы или сертификаты, которые относятся к IT. Если у Вас есть несколько образовательных уровней, давайте начнем с самого\n",
            " последнего.\n",
            "Клиент: stop\n"
          ]
        }
      ]
    }
  ]
}